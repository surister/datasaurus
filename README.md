Datasaurus is a Data Engineering framework written in Python 3.8, 3.9, 3.10 and 3.11

It is based in Polars and heavily influenced by Django.

Datasaurus offers an opinionated, feature-rich and powerful framework to help you write
data pipelines, ETLs or data manipulation programs.

[Documentation]() (TODO)
## It supports:
- âœ… Fully support read/write operations.
- â­• Not yet but will be implemented.
- ğŸ’€ Won't be implemented in the near future.

### Storages:
- Sqlite âœ…
- PostgresSQL âœ…
- MySQL âœ…
- Mariadb âœ…
- Local Storage âœ…
- Azure blob storage â­•
- AWS S3 â­•


### Formats:
- CSV âœ…
- JSON âœ…
- PARQUET âœ…
- EXCEL âœ…
- AVRO âœ…
- TSV â­•
- SQL â­• (Like sql inserts)
- 
### Features:
- Delta Tables â­•
- Field validations â­•

## Simple example
```python
# settings.py 
from datasaurus.core.storage import PostgresStorage, StorageGroup, SqliteStorage
from datasaurus.core.models import StringColumn, IntegerColumn

# We set the environment that will be used.
os.environ['DATASAURUS_ENVIRONMENT'] = 'dev'

class ProfilesData(StorageGroup):
    dev = SqliteStorage(path='/data/data.sqlite')
    live = PostgresStorage(username='user', password='user', host='localhost', database='postgres')

    
# models.py
from datasaurus.core.models import Model, StringColumn, IntegerColumn

class ProfileModel(Model):
    id = IntegerColumn()
    username = StringColumn()
    mail = StringColumn()
    sex = StringColumn()

    class Meta:
        storage = ProfilesData
        table_name = 'PROFILE'

```

We can access the raw Polars dataframe with 'Model.df', it's lazy, meaning it will only load the
data if we access the attribute.

```py
>>> ProfileModel.df
shape: (100, 4)
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ id  â”† username           â”† mail                     â”† sex â”‚
â”‚ --- â”† ---                â”† ---                      â”† --- â”‚
â”‚ i64 â”† str                â”† str                      â”† str â”‚
â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•¡
â”‚ 1   â”† ehayes             â”† colleen63@hotmail.com    â”† F   â”‚
â”‚ 2   â”† thompsondeborah    â”† judyortega@hotmail.com   â”† F   â”‚
â”‚ 3   â”† orivera            â”† iperkins@hotmail.com     â”† F   â”‚
â”‚ 4   â”† ychase             â”† sophia92@hotmail.com     â”† F   â”‚
â”‚ â€¦   â”† â€¦                  â”† â€¦                        â”† â€¦   â”‚
â”‚ 97  â”† mary38             â”† sylvia80@yahoo.com       â”† F   â”‚
â”‚ 98  â”† charlessteven      â”† usmith@gmail.com         â”† F   â”‚
â”‚ 99  â”† plee               â”† powens@hotmail.com       â”† F   â”‚
â”‚ 100 â”† elliottchristopher â”† wilsonbenjamin@yahoo.com â”† M   â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜

```

We could now create a new model whose data is created from ProfileModel

```python
class FemaleProfiles(Model):
    id = IntegerField()
    profile_id = IntegerField()
    mail = StringField()

    def calculate_data(self):
        return (
            ProfileModel.df
            .filter(ProfileModel.sex == 'F')
            .with_row_count('new_id')
            .with_columns(
                pl.col('new_id')
            )
            .with_columns(
                pl.col('id').alias('profile_id')
            )
        )

    class Meta:
        recalculate = 'if_no_data_in_storage'
        storage = ProfilesData
        table_name = 'PROFILE_FEMALES'
```
Et voilÃ¡! the columns will be auto selected from the column definitions (id, profile_id and email).

If we now call:
```python
FemaleProfiles.df
```

It will check if the dataframe exists in the storage and if it does not, it will 'calculate' it again
from calculate_data and save it to the Storage, this parameter can also be set to 'always'.


You can also move data to different environments or storages, making it easy to change formats or
move data around:

```python
FemaleProfiles.save(to=ProfilesData.live)
```

Effectively moving data from SQLITE (dev) to PostgreSQL (live), 

```python
# Can also change formats
FemaleProfiles.save(to=ProfilesData.otherenvironment, format=LocalFormat.JSON)
FemaleProfiles.save(to=ProfilesData.otherenvironment, format=LocalFormat.CSV)
FemaleProfiles.save(to=ProfilesData.otherenvironment, format=LocalFormat.PARQUET)
```
